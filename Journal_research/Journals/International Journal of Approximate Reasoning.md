# Aim and scope close to DP
- The _International Journal of Approximate Reasoning_ is intended to serve as a forum for the treatment of **imprecision** and **uncertainty** in **Artificial** and **Computational Intelligence**, covering both the foundations of <mark style="background: #EDAC0CCF;">uncertainty theories</mark>, and the design of i<mark style="background: #EDAC0CCF;">ntelligent systems for scientific and engineering applications</mark>. It publishes high-quality research papers describing <mark style="background: #EDAC0CCF;">theoretical developments or innovative applications</mark>, as well as review articles on topics of general interest.
- Relevant topics include, but are not limited to, <mark style="background: #EDAC0CCF;">probabilistic reasoning</mark> and <mark style="background: #EDAC0CCF;">Bayesian networks</mark>, imprecise probabilities, random sets, <mark style="background: #EDAC0CCF;">belief functions</mark> (Dempster-Shafer theory), possibility theory, fuzzy sets, rough sets, decision theory, non-additive measures and integrals, qualitative reasoning about uncertainty, comparative probability orderings, game-theoretic probability, <mark style="background: #EDAC0CCF;">default reasoning</mark>, nonstandard logics, argumentation systems, inconsistency tolerant reasoning, elicitation techniques, philosophical foundations and psychological models of uncertain reasoning.
- Domains of application for <mark style="background: #EDAC0CCF;">uncertain reasoning systems</mark> include risk analysis and assessment, information retrieval and database design, <mark style="background: #EDAC0CCF;">information fusion</mark>, machine learning, data and web mining, computer vision, image and signal processing, intelligent data analysis, statistics, <mark style="background: #EDAC0CCF;">multi-agent systems</mark>, etc.

# Notes
- Publisher: ELSEVIER SCIENCE INC
- Filters: 2022-2024
- Chosen Journal
# Similar articles 

### [ A novel information fusion method using improved entropy measure in multi-source incomplete interval-valued datasets](https://www.sciencedirect.com/science/article/pii/S0888613X23002128?via%3Dihub)
- Published: 01.01.2024
- Similarity: 
	- Multi-source data is a comprehensive data type that combines <mark style="background: #EDAC0CCF;">multiple sources of information</mark> or datasets. Compared to point-valued data, interval-valued data provides a more accurate representation of the uncertainty and variability associated with objects. In practical situations, data obtained from multiple sources may contain missing values for various reasons. Therefore, it is essential to develop multi-source <mark style="background: #EDAC0CCF;">information fusion</mark> technology in order to achieve information fusion or information extraction from multi-source incomplete data. This paper aims to explore the information fusion problem of multi-source incomplete interval-valued datasets. The primary contributions of this study involve <mark style="background: #EDAC0CCF;">utilizing the principle of statistical distribution and KL divergence to establish a metric for measuring the similarity between intervals</mark>. Firstly, this approach helps to reduce the problem of disregarding internal information within interval values, which can result in the loss of valuable information. Secondly, we establish an interval fuzzy similarity relation based on the mentioned concept of similarity among interval values. Moreover, we investigate the uncertainty measurement of incomplete interval-valued decision datasets and design an emerging information entropy fusion method. Finally, we comprehensively evaluate the effectiveness of the proposed method. Experimental results indicate that the proposed approach has advantage over the maximum, minimum, mean, and information entropy fusion method based on tolerance relationship. In addition, the distance metric used in this article can improve the fusion classification effect compared to several common interval-valued distance measures.
### [Toward credible belief base revision](https://www.sciencedirect.com/science/article/pii/S0888613X2300138X?via%3Dihub)
- Published: 01.11.2023
- Similarity: 
	- This paper deals with belief base revision, a form of <mark style="background: #EDAC0CCF;">belief change</mark> which consists in restoring consistency with the intention of <mark style="background: #EDAC0CCF;">incorporating a new piece of information from the environment</mark>, while minimally modifying the agent's belief state represented by a finite set of propositional formulas. In an effort to guarantee more reliability and rationality for real applications while performing revision, we come up with the idea of credible belief base revision. We define two new formula-based revision operators using tools offered by evidence theory. These operators, uniformly presented in the same spirit as [92,13], stem from consistent sub-bases maximal with respect to credibility instead of set inclusion or cardinality. Logical properties and productivity of inference from these operators are established, along with complexity results. (c) 2023 Elsevier Inc. All rights reserved.
### [Using scoring functions in a group decision-making procedure with heterogeneous experts and qualitative assessments](https://www.sciencedirect.com/science/article/pii/S0888613X23001354?via%3Dihub)
- Published: 01.10.2023
- Similarity: 
	- In this paper, we propose a group <mark style="background: #EDAC0CCF;">decision-making</mark> procedure to rank alternatives in the context of ordered qualitative scales that not necessarily are uniform (the proximities between consecutive terms of the scales can be perceived as different). The procedure manages two ordered qualitative scales. One of them is used to determine the <mark style="background: #EDAC0CCF;">weights of the experts</mark> according to their expertise, taking into account the assessments given by a <mark style="background: #EDAC0CCF;">decision-maker</mark> to <mark style="background: #EDAC0CCF;">the experts</mark>. And another one, that is used by <mark style="background: #EDAC0CCF;">the experts</mark> to assess the alternatives. In order to assign numerical scores to the linguistic terms of the ordered qualitative scales, we have introduced and analyzed some scoring functions. They are based on the concept of ordinal proximity measure that properly represents the ordinal proximities between the linguistic terms of the ordered qualitative scales. 
### [Achieving threshold consistency in three-way group decision using optimization methodology and expert-weight-updating-strategy](https://www.sciencedirect.com/science/article/pii/S0888613X23000531?via%3Dihub)
- Published: 01.07.2023
- Similarity: 
	- How to improve and achieve a group consistency under three-way group decision is a key research issue that has recently attracted more and more attention. To deal with this issue, this paper proposes an <mark style="background: #EDAC0CCF;">expert-weight-updating-based</mark>approach to achieve a threshold consistency under three-way group decision with various opinions of linguistic intuitionistic fuzzy numbers. First, we use a linguistic intuitionistic fuzzy number (LIFN) to evaluate loss functions among experts due to its advantages in uncertain evaluations, and establish a fundamental model of decision-theoretic rough sets <mark style="background: #EDAC0CCF;">with different opinions of multiple experts</mark>. Then, we put forward a single optimization model that is an extension of our previous model, and utilize a mapping technique with such optimization methodology to generate numerical thresholds of individual <mark style="background: #EDAC0CCF;">experts</mark>. Second, we employ the normalized Hamming distance to define concepts of <mark style="background: #EDAC0CCF;">similarity measure</mark> and group consensus index based on individual thresholds. Then, we design a method to derive <mark style="background: #EDAC0CCF;">initial weights</mark>, a s<mark style="background: #EDAC0CCF;">trategy to update weights of experts</mark>, and an <mark style="background: #EDAC0CCF;">expert-weight-updating-based</mark> algorithm to achieve a consensus of group thresholds. Third, via this algorithm, we develop a three-way group decision consensus achieving approach based on linguistic intuitionistic fuzzy <mark style="background: #EDAC0CCF;">opinions </mark>with multiple experts. Finally, some experiments and comparative analysis are performed to verify a convergence of our algorithm and the effectiveness of our approach. (c) 2023 Elsevier Inc. All rights reserved.

### [On the derivation of weights from incomplete pairwise comparisons matrices via spanning trees with crisp and fuzzy confidence levels](https://www.sciencedirect.com/science/article/pii/S0888613X22001268?via%3Dihub)
- Published: 01.11.2022
- Similarity: 
	- In this paper, we propose a new method for the derivation of a priority vector from an incomplete pairwise comparisons (PC) matrix. We assume that each entry of a PC matrix provided by <mark style="background: #EDAC0CCF;">an expert</mark> is also evaluated in terms of the <mark style="background: #EDAC0CCF;">expert's confidence</mark> in a particular judgment. Then, from corresponding graph representations of a given PC matrix, all spanning trees are found. For each spanning tree, a unique priority vector is obtained with the weight corresponding to the confidence levels of entries that constitute this tree. At the end, the final priority vector is obtained through an aggregation of priority vectors achieved from all spanning trees. <mark style="background: #EDAC0CCF;">Confidence levels</mark> are modeled by real (crisp) numbers and triangular fuzzy numbers. Numerical examples and comparisons with other methods are also provided. Last, but not least, we introduce a new formula for an upper bound of the number of spanning trees, so that a <mark style="background: #EDAC0CCF;">decision maker </mark>gains knowledge (in advance) on how computationally demanding the proposed method is for a given PC matrix.(C) 2022 Elsevier Inc. All rights reserved.

### [Formalization and implementation of credibility dynamics through prioritized multiple revision](https://www.sciencedirect.com/science/article/pii/S0888613X22000640?via%3Dihub)
- Published: 01.08.2022
- Similarity: 
	- In this work, we focus on credibility dynamics. The <mark style="background: #EDAC0CCF;">trust</mark> or credibility associated with a <mark style="background: #EDAC0CCF;">set of agents</mark> is represented by a pairwise comparison partial order of agents called credibility order. In this paper, we formalize a prioritized multiple revision operator that can be used to revise one credibility order by another credibility order. We introduce a set of postulates for this change operator, and we show that our proposed operator satisfies those postulates. We will also introduce a computer application we have developed to provide a complete implementation of our approach. The application has an intuitive graphical user interface to handle credibility orders, apply the change operator, and has some visual tools to explain the revision process. (C) 2022 Elsevier Inc. All rights reserved.

### [A Bayesian hierarchical score for structure learning from related data sets](https://www.sciencedirect.com/science/article/pii/S0888613X21001973?via%3Dihub)
- Published: 01.03.2022
- Similarity: 
	- Score functions for learning the structure of Bayesian networks in the literature assume that data are a homogeneous set of observations; whereas it is often the case that they comprise different related, but not homogeneous, data sets collected in different ways. In this paper we propose a new Bayesian Dirichlet score, which we call <mark style="background: #EDAC0CCF;">Bayesian Hierarchical Dirichlet (BHD)</mark>. The proposed score is based on a <mark style="background: #EDAC0CCF;">hierarchical model</mark> that <mark style="background: #EDAC0CCF;">pools information across data sets</mark> to learn a single encompassing network structure, while taking into account the differences in their probabilistic structures. We derive a closed form expression for BHD using a variational approximation of the marginal likelihood, we study the associated computational cost and we evaluate its performance using simulated data. We find that, when data comprise multiple related data sets, BHD outperforms the Bayesian Dirichlet equivalent uniform (BDeu) score in terms of reconstruction accuracy as measured by the Structural Hamming distance, and that it is as accurate as BDeu when data are homogeneous. This improvement is particularly clear when either the number of variables in the network or the number of observations is large. Moreover, the estimated networks are sparser and therefore more interpretable than those obtained with BDeu thanks to a lower number of false positive arcs.(C) 2021 The Author(s). Published by Elsevier Inc.




